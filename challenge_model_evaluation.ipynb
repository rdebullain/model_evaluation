{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Exercise\n",
    "\n",
    "## Regression evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:07.040365Z",
     "start_time": "2020-04-27T07:41:07.036332Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X,y = make_regression(n_features=10, n_samples=1000, noise=10)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:07.456392Z",
     "start_time": "2020-04-27T07:41:07.444403Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "y_lr = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating ridge regression\n",
    "rr = Ridge(alpha=0.1)\n",
    "rr.fit(X,y)\n",
    "y_rr = rr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________\n",
    "## Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error (MAE) is a measure used to quantify the accuracy of predictions in regression problems. It is calculated as the average of the absolute differences between the predicted and actual values. \n",
    "\n",
    "Here's the formula for MAE: MAE = (1/n) * Σ|y - ŷ| \n",
    "\n",
    "Where:\n",
    "- `n` is the total number of data points\n",
    "- `y` is the actual value\n",
    "- `ŷ` is the predicted value\n",
    "- `Σ` denotes the sum over all data points\n",
    "\n",
    "The MAE is a linear score, which means all individual differences are weighted equally in the average. It's measured in the same units as the data, which helps interpretation. \n",
    "\n",
    "A smaller MAE suggests a better fit of the model to the data. However, because it averages the absolute values of the residuals, it might not reflect the impact of large outliers as much as other metrics like Mean Squared Error (MSE). \n",
    "\n",
    "In terms of interpretation, if the MAE is 0, the model is perfect. Otherwise, the MAE tells you how much you can expect your predictions to deviate from the actual values, on average. For example, if you're predicting house prices and your MAE is 30,000, you can expect your predictions to be off by about $30,000 on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import **mean_absolute_error** from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:08.798377Z",
     "start_time": "2020-04-27T07:41:07.948605Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* compute MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:08.844975Z",
     "start_time": "2020-04-27T07:41:08.840746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Linear Regression: 7.920336750100665\n",
      "MAE for Ridge Regression: 7.921267800898699\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have these variables:\n",
    "# y: the actual values\n",
    "# y_lr: predictions from the linear regression model\n",
    "# y_rr: predictions from the ridge regression model\n",
    "\n",
    "mae_linear = mean_absolute_error(y, y_lr)\n",
    "mae_ridge = mean_absolute_error(y, y_rr)\n",
    "\n",
    "print(f\"MAE for Linear Regression: {mae_linear}\")\n",
    "print(f\"MAE for Ridge Regression: {mae_ridge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* According to MAE, what is the better model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean Absolute Error (MAE) is a measure of prediction error where lower values indicate better predictive accuracy. In your case, the Linear Regression model has a slightly lower MAE (7.877229155042664) compared to the Ridge Regression model (7.877458410421922).\n",
    "\n",
    "Therefore, based on this metric alone, the Linear Regression model is performing slightly better. However, it's important to consider other metrics and the specific context of your problem as well when choosing the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________\n",
    "## R2 - Coefficient of Determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of determination, often denoted as R^2 or r-squared, is a statistical measure that shows the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model.\n",
    "\n",
    "R-squared values range from 0 to 1. An R-squared of 100 percent indicates that all changes in the dependent variable are completely explained by changes in the independent variable(s). Conversely, an R-squared of 0 percent indicates that the model explains none of the variability of the response data around its mean.\n",
    "\n",
    "Here's how to interpret it:\n",
    "\n",
    "- R-squared = 0%: The model explains none of the variability of the response data around its mean.\n",
    "- R-squared = 50%: The model explains half the variability of the response data around its mean.\n",
    "- R-squared = 100%: The model explains all the variability of the response data around its mean.\n",
    "\n",
    "In general, the higher the R-squared, the better the model fits your data. However, there are important conditions where this is not the case. For instance, if a model is overfitted, it may have a high R-squared value but make poor predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import **r2_score** from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:09.361905Z",
     "start_time": "2020-04-27T07:41:09.357486Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* compute R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:09.700385Z",
     "start_time": "2020-04-27T07:41:09.692404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for y_lr:  0.9977530115470379\n",
      "R-squared for y_rr:  0.997753000772718\n"
     ]
    }
   ],
   "source": [
    "r2_score_lr = r2_score(y, y_lr)\n",
    "r2_score_rr = r2_score(y, y_rr)\n",
    "\n",
    "print(\"R-squared for y_lr: \", r2_score_lr)\n",
    "print(\"R-squared for y_rr: \", r2_score_rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* According to R2, what is the better model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared values for both models are extremely close, but the model for `y_lr` has a slightly higher R-squared value (0.9969564483605733) compared to the model for `y_rr` (0.9969564381047377). \n",
    "\n",
    "Therefore, based solely on the R-squared values, the `y_lr` model is slightly better as it explains a marginally higher proportion of the variance in the dependent variable. However, the difference is so small that it might not be practically significant. Other factors such as the complexity of the model, interpretability, and performance on unseen data should also be considered when choosing the better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (Stretch) use predictions from linear regression and compute adjusted R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:10.384626Z",
     "start_time": "2020-04-27T07:41:10.369223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared for y_lr:  0.997750760055602\n",
      "Adjusted R-squared for y_rr:  0.9977507492704862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Assuming y_true is the actual values\n",
    "r2_lr = r2_score(y, y_lr)\n",
    "r2_rr = r2_score(y, y_rr)\n",
    "\n",
    "# n is the number of observations and p is the number of predictors\n",
    "n = len(y)\n",
    "p = 1  # change this to the number of predictors in your model\n",
    "\n",
    "adjusted_r2_lr = 1 - (1 - r2_lr) * (n - 1) / (n - p - 1)\n",
    "adjusted_r2_rr = 1 - (1 - r2_rr) * (n - 1) / (n - p - 1)\n",
    "\n",
    "print(\"Adjusted R-squared for y_lr: \", adjusted_r2_lr)\n",
    "print(\"Adjusted R-squared for y_rr: \", adjusted_r2_rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________\n",
    "## Classification evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:11.344672Z",
     "start_time": "2020-04-27T07:41:11.339435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X,y = make_classification(n_features=10, n_samples=1000, n_classes=2)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating linear regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X,y)\n",
    "y_lr = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating ridge regression\n",
    "rr = RidgeClassifier(alpha=0.1)\n",
    "rr.fit(X,y)\n",
    "y_rr = rr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision score\n",
    "\n",
    "**Write the definition to the Precision score below and how to interpret it?**\n",
    "> *The Precision score refers too....*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import **precision_score** from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:12.147881Z",
     "start_time": "2020-04-27T07:41:12.143399Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* compute precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:12.631435Z",
     "start_time": "2020-04-27T07:41:12.625996Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:13.071881Z",
     "start_time": "2020-04-27T07:41:13.064584Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall score\n",
    "\n",
    "**Write the definition to the Recall score below and how to interpret it?**\n",
    "> *The Recall score refers too....*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import **recal_score** from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:13.908070Z",
     "start_time": "2020-04-27T07:41:13.903483Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* compute recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:14.264301Z",
     "start_time": "2020-04-27T07:41:14.258735Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:14.590250Z",
     "start_time": "2020-04-27T07:41:14.586420Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve\n",
    "\n",
    "**What is the ROC curve? How do you interpret it?**\n",
    "> *The ROC curve refers too....*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import **roc_curve** from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:15.347036Z",
     "start_time": "2020-04-27T07:41:15.343389Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* compute and store ROC curve values in fpr, tpr, thresholds variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:15.801469Z",
     "start_time": "2020-04-27T07:41:15.796150Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:16.378369Z",
     "start_time": "2020-04-27T07:41:16.115532Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:16.834163Z",
     "start_time": "2020-04-27T07:41:16.480665Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Loss score\n",
    "**What is the Log-Loss score? How do you interpret it?**\n",
    "> *The Log-Loss score refers too...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import **log_loss** from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:17.071277Z",
     "start_time": "2020-04-27T07:41:17.063336Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* compute log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:18.251211Z",
     "start_time": "2020-04-27T07:41:18.244484Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T07:41:18.588367Z",
     "start_time": "2020-04-27T07:41:18.579532Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: According to metrics above, which one is the better model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
